{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
    "\n",
    "\n",
    "# Evolutionary Computation\n",
    "\n",
    "## 5.3 Deep Neuroevolution\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://d9w.github.io/evolution/\">https://d9w.github.io/evolution/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neuroevolution\n",
    "\n",
    "Artificial neural networks are commonly used today in many applications, from phone apps to automatic piloting systems to search engines. These machine learning models contain many parameters and are usually optimized with stochastic gradient descent. However, evolutionary strategies can also be a great tool for optimizing neural network parameters, especially when there isn't a clear direction the training of the network should take. This is the case for reinforcement learning, so we'll look at a classic RL task in this section.\n",
    "\n",
    "Because of the success of deep learning, where neural network architectures are \"deep\" by having many layers, this field is sometimes called deep neuroevolution. However, remember from tutorial 4 that researchers have been evolving neural networks long before the advent of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In today's notebook, I'll be using some Python RL environments and using PyCall to interact with them in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using Conda\n",
    "using Flux\n",
    "include(\"cmaes.jl\");\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can write a construction method which just uses zeros as all weights and biases. We'll fill these with the genetic information later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_CNN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct convol\n",
    "    w ::AbstractArray{Float64}\n",
    "    b ::AbstractArray{Float64}\n",
    "end\n",
    "\n",
    "struct my_CNN\n",
    "    c1 :: convol\n",
    "    c2 :: convol\n",
    "    c3 :: convol\n",
    "end\n",
    "\n",
    "function my_CNN(f1::Int,c1_in::Int,c1_out::Int,f2::Int,c2_in::Int,c2_out::Int,c3_in::Int,c3_out::Int)\n",
    "    c1 = convol(zeros(f1,f1,c1_in,c1_out),zeros(c1_out))\n",
    "    c2 = convol(zeros(f2,f2,c2_in,c2_out),zeros(c2_out))\n",
    "    c3 = convol(zeros(c3_out,c3_in),zeros(c3_out))\n",
    "    my_CNN(c1,c2,c3)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_cnn (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_cnn(ann,inputs)\n",
    "    y = Flux.Conv(ann.c1.w,ann.c1.b,σ;stride=3)(inputs)\n",
    "    y = Flux.MaxPool((2,2),stride=2)(y)\n",
    "    y = Flux.Conv(ann.c2.w,ann.c2.b,σ;stride=3)(y)\n",
    "    y = Flux.MeanPool((2,2),stride=4)(y)\n",
    "    y = flatten(y)\n",
    "    y = Flux.Dense(ann.c3.w,ann.c3.b,σ)(y)\n",
    "    y = (y .> 0.5) .* 1 \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'retro' from 'C:\\\\Users\\\\Kinza\\\\.julia\\\\conda\\\\3\\\\lib\\\\site-packages\\\\retro\\\\__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retro = pyimport_conda(\"retro\",\"gym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "syntax: more than one semicolon in argument list",
     "output_type": "error",
     "traceback": [
      "syntax: more than one semicolon in argument list",
      "",
      "Stacktrace:",
      " [1] top-level scope at C:\\Users\\Kinza\\.julia\\packages\\IJulia\\DrVMH\\src\\kernel.jl:52"
     ]
    }
   ],
   "source": [
    "function play_env(ann; render=false;train=true)\n",
    "    env = retro.make(\"SonicTheHedgehog-Genesis\",\"GreenHillZone.Act1\")\n",
    "    ob = env.reset()\n",
    "    total_reward = 0.0\n",
    "    done = false\n",
    "    #inx, iny, inc = env.observation_space.shape\n",
    "    #inx = floor(Int,inx/8)\n",
    "    #iny = floor(Int,iny/8)\n",
    "    \n",
    "    max_fitness = 0\n",
    "    fitness = 0\n",
    "    counter = 0\n",
    "    xpos = 0\n",
    "    xpos_max = 0\n",
    "    frame = 0\n",
    "    while ~done\n",
    "        if render\n",
    "            frame+=1\n",
    "            env.render()\n",
    "        end\n",
    "        \n",
    "        ob = Flux.unsqueeze(ob,4)\n",
    "        action = compute_cnn(ann,ob)\n",
    "        #println(\"action = \",action)\n",
    "        \n",
    "        ob, reward, done, info = env.step(action)\n",
    "    \n",
    "        fitness += reward\n",
    "\n",
    "        xpos = info[\"x\"]\n",
    "        xpos_end = info[\"screen_x_end\"]\n",
    "\n",
    "\n",
    "        if xpos > xpos_max\n",
    "            fitness += 1\n",
    "            xpos_max = xpos\n",
    "        end\n",
    "\n",
    "        if xpos == xpos_end && xpos > 500\n",
    "            fitness += 100000\n",
    "            done = True\n",
    "        end\n",
    "        \n",
    "        if train == true \n",
    "            if counter>700 && fitness<=2000\n",
    "                done = true\n",
    "                println(\"max steps reached\")\n",
    "            end\n",
    "\n",
    "            if counter>1400 && fitness>2000\n",
    "                done = true\n",
    "                println(\"Good fitness but max steps reached\")\n",
    "            end\n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "    env.close()\n",
    "    fitness\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_CNN(genes::Array{Float64})\n",
    "    ann = my_CNN(12,3,4,8,4,1,12,12)\n",
    "    layers = [ann.c1.w, ann.c1.b, ann.c2.w, ann.c2.b,ann.c3.w,ann.c3.b]\n",
    "    L = 1\n",
    "    j = 1\n",
    "    for i in eachindex(genes)\n",
    "        if j > length(layers[L])\n",
    "            L += 1\n",
    "            j = 1\n",
    "        end\n",
    "        layers[L][j] = genes[i]\n",
    "        j += 1\n",
    "    end\n",
    "    ann\n",
    "end\n",
    "\n",
    "function objective(genes::Array{Float64})\n",
    "    ann = my_CNN(genes)\n",
    "    -play_env(ann;render=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 12*12*3*4+4+8*8*4*1+1+12*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation = 1, fitness = 193.0, elapsed time = 1088.994999885559\n",
      "generation = 2, fitness = 438.0, elapsed time = 1195.7709999084473\n",
      "generation = 3, fitness = 501.0, elapsed time = 804.7369999885559\n",
      "generation = 4, fitness = 254.0, elapsed time = 1622.1989998817444\n",
      "generation = 5, fitness = 551.0, elapsed time = 969.0030000209808\n",
      "generation = 6, fitness = 755.0, elapsed time = 701.5469999313354\n",
      "generation = 7, fitness = 177.0, elapsed time = 469.7220001220703\n",
      "generation = 8, fitness = 467.0, elapsed time = 609.2249999046326\n",
      "generation = 9, fitness = 277.0, elapsed time = 503.93499994277954\n",
      "generation = 10, fitness = 652.0, elapsed time = 688.7960000038147\n",
      "generation = 11, fitness = 233.0, elapsed time = 500.606999874115\n",
      "generation = 12, fitness = 609.0, elapsed time = 545.6499998569489\n",
      "generation = 13, fitness = 877.0, elapsed time = 563.4580001831055\n",
      "generation = 14, fitness = 389.0, elapsed time = 476.19599986076355\n",
      "generation = 15, fitness = 213.0, elapsed time = 539.154000043869\n",
      "generation = 16, fitness = 159.0, elapsed time = 511.0550000667572\n",
      "generation = 17, fitness = 265.0, elapsed time = 507.6119999885559\n",
      "generation = 18, fitness = 489.0, elapsed time = 801.2920000553131\n",
      "generation = 19, fitness = 190.0, elapsed time = 569.5869998931885\n",
      "generation = 20, fitness = 365.0, elapsed time = 565.2780001163483\n",
      "generation = 21, fitness = 213.0, elapsed time = 442.8369998931885\n",
      "generation = 22, fitness = 477.0, elapsed time = 960.8810000419617\n",
      "generation = 23, fitness = 188.0, elapsed time = 481.3430001735687\n",
      "generation = 24, fitness = 525.0, elapsed time = 476.82999992370605\n",
      "generation = 25, fitness = 102.0, elapsed time = 431.25\n",
      "generation = 26, fitness = 111.0, elapsed time = 398.42599987983704\n",
      "generation = 27, fitness = 224.0, elapsed time = 430.7630000114441\n",
      "generation = 28, fitness = 660.0, elapsed time = 442.7420001029968\n",
      "generation = 29, fitness = 273.0, elapsed time = 499.7720000743866\n",
      "generation = 30, fitness = 37.0, elapsed time = 433.25\n",
      "generation = 31, fitness = 83.0, elapsed time = 401.8829998970032\n",
      "generation = 32, fitness = 111.0, elapsed time = 560.6310000419617\n",
      "generation = 33, fitness = 567.0, elapsed time = 537.5770001411438\n",
      "generation = 34, fitness = 472.0, elapsed time = 509.5329999923706\n",
      "generation = 35, fitness = 152.0, elapsed time = 500.2590000629425\n",
      "generation = 36, fitness = 195.0, elapsed time = 492.481999874115\n",
      "generation = 37, fitness = 187.0, elapsed time = 492.46299982070923\n",
      "generation = 38, fitness = 121.0, elapsed time = 617.1160001754761\n",
      "generation = 39, fitness = 293.0, elapsed time = 492.2149999141693\n",
      "generation = 40, fitness = 140.0, elapsed time = 503.614000082016\n",
      "generation = 41, fitness = 451.0, elapsed time = 542.7669999599457\n",
      "generation = 42, fitness = 132.0, elapsed time = 468.6879999637604\n",
      "generation = 43, fitness = 124.0, elapsed time = 478.04299998283386\n",
      "generation = 44, fitness = 112.0, elapsed time = 515.672000169754\n",
      "generation = 45, fitness = 120.0, elapsed time = 487.0809998512268\n",
      "generation = 46, fitness = 133.0, elapsed time = 519.2330000400543\n",
      "generation = 47, fitness = 224.0, elapsed time = 470.6270000934601\n",
      "generation = 48, fitness = 113.0, elapsed time = 537.8229999542236\n",
      "generation = 49, fitness = 255.0, elapsed time = 1370.2469999790192\n",
      "generation = 50, fitness = 201.0, elapsed time = 1105.3899998664856\n",
      "generation = 51, fitness = 196.0, elapsed time = 1566.266000032425\n",
      "generation = 52, fitness = 143.0, elapsed time = 1559.0620000362396\n",
      "generation = 53, fitness = 136.0, elapsed time = 1184.1840000152588\n",
      "generation = 54, fitness = 176.0, elapsed time = 1206.3270001411438\n",
      "generation = 55, fitness = 143.0, elapsed time = 1178.848000049591\n",
      "generation = 56, fitness = 129.0, elapsed time = 1243.111999988556\n",
      "generation = 57, fitness = 96.0, elapsed time = 1086.218999862671\n",
      "generation = 58, fitness = 112.0, elapsed time = 1026.5560002326965\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled), ::Base.RefValue{Task}) at .\\task.jl:654",
      " [2] wait() at .\\task.jl:710",
      " [3] wait(::Base.GenericCondition{Base.Threads.SpinLock}) at .\\condition.jl:106",
      " [4] _wait(::Task) at .\\task.jl:238",
      " [5] wait(::Task) at .\\task.jl:265",
      " [6] macro expansion at .\\threadingconstructs.jl:69 [inlined]",
      " [7] conv_im2col!(::Array{Float64,5}, ::Array{Float64,5}, ::Array{Float64,5}, ::DenseConvDims{3,(8, 8, 1),4,1,(3, 3, 1),(0, 0, 0, 0, 0, 0),(1, 1, 1),false}; col::Array{Float64,3}, alpha::Float64, beta::Float64) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\impl\\conv_im2col.jl:49",
      " [8] conv_im2col! at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\impl\\conv_im2col.jl:30 [inlined]",
      " [9] #conv!#41 at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:53 [inlined]",
      " [10] conv!(::Array{Float64,5}, ::Array{Float64,5}, ::Array{Float64,5}, ::DenseConvDims{3,(8, 8, 1),4,1,(3, 3, 1),(0, 0, 0, 0, 0, 0),(1, 1, 1),false}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:53",
      " [11] conv!(::Array{Float64,4}, ::Array{Float64,4}, ::Array{Float64,4}, ::DenseConvDims{2,(8, 8),4,1,(3, 3),(0, 0, 0, 0),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:70",
      " [12] conv! at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:70 [inlined]",
      " [13] conv(::Array{Float64,4}, ::Array{Float64,4}, ::DenseConvDims{2,(8, 8),4,1,(3, 3),(0, 0, 0, 0),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:116",
      " [14] conv(::Array{Float64,4}, ::Array{Float64,4}, ::DenseConvDims{2,(8, 8),4,1,(3, 3),(0, 0, 0, 0),(1, 1),false}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:114",
      " [15] (::Conv{2,4,typeof(σ),Array{Float64,4},Array{Float64,1}})(::Array{Float64,4}) at C:\\Users\\Kinza\\.julia\\packages\\Flux\\f1bXf\\src\\layers\\conv.jl:137",
      " [16] compute_cnn(::my_CNN, ::Array{UInt8,4}) at .\\In[3]:4",
      " [17] play_env(::my_CNN; render::Bool) at .\\In[5]:23",
      " [18] objective(::Array{Float64,1}) at .\\In[6]:19",
      " [19] step!(::CMAES, ::typeof(objective)) at C:\\Users\\Kinza\\Documents\\GitHub\\PAE\\Kinza\\CMAES-Julia\\cmaes.jl:47",
      " [20] top-level scope at .\\In[8]:8"
     ]
    }
   ],
   "source": [
    "best = nothing\n",
    "best_fit = -Inf\n",
    "c = CMAES(N=N, µ=20, λ=20, τ=sqrt(N), τ_c=N^2, τ_σ=sqrt(N))\n",
    "i=0\n",
    "fitness = []\n",
    "while best_fit <2000 \n",
    "    i+=1\n",
    "    start = time()\n",
    "    step!(c, objective)\n",
    "    bestind = argmin(c.F_λ)\n",
    "    maxfit = -c.F_λ[bestind]\n",
    "    print(\"generation = \",i, \", fitness = \", maxfit)\n",
    "    fitness = [fitness; maxfit]\n",
    "    if maxfit > best_fit\n",
    "        best = copy(c.offspring[bestind])\n",
    "        best_fit = maxfit\n",
    "    end\n",
    "    println(\", elapsed time = \",time()-start)\n",
    "end\n",
    "\n",
    "i=1:length(fitness)\n",
    "plot(i,fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ann = my_CNN(best)\n",
    "using BSON: @save\n",
    "@save \"mymodel.bson\" ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_env(ann; render=true,train=false)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
